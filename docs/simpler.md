---
layout: default
title: "CFP:  Less is More"
description: "CFP: Less is More"
nav_order: 2
---

# Call for papers, Less is More
{: .fs-9 }

Submissions to this track musht come  much come with a cover letter stating that they wish to be reviewed as "less is more" paper.

Over the years, there have been many reports  that very simple models can perform exceptionally well [^am] [^ho] [^ko] [^me] [^ta] [^za]
and that such simpler models are essential for human comprehension of a topic [^pi].
Yet where are the researchers asking ``say, does
that mean that we could make software analytics simpler and more comprehensible''?

[^am]:Amritanshu Agrawal, Wei Fu, Di Chen, Xipeng Shen, and Tim Menzies. 2019. How to “dodge” complex software analytics. IEEE Transactions on Software Engineering 47, 10 (2019), 2182–2194.
[^gi]: Gigerenzer G. Why Heuristics Work. Perspect Psychol Sci. 2008 Jan;3(1):20-9. doi: 10.1111/j.1745-6916.2008.00058.x. PMID: 26158666.
[^ho]: Robert C. Holte. 1993. Very Simple Classification Rules Perform Well on Most Commonly Used Datasets. Machine Learning 11 (1993), 63–90
[^ko]: Ron Kohavi and George H. John. 1997. Wrappers for Feature Subset Selection. Artificial Intelligence 97, 1-2 (1997), 273–324. 
[^me] Tim Menzies, Burak Turhan, Ayse Bener, Gregory Gay, Bojan Cukic, and Yue Jiang. 2008. Implications of ceiling effects in defect predictors. In Proceedings of the 4th international workshop on Predictor models in software engineering. 47–54.
[^pi]: Nathaniel D Phillips, Hansjoerg Neth, Jan K Woike, and Wolfgang Gaissmaier. 2017. FFTrees: A toolbox to create, visualize, and evaluate fast-and-frugal decision trees. Judgment and Decision Making 12, 4 (2017), 344–368.
[^ta]: Vali Tawosi, Rebecca Moussa, and Federica Sarro. 2023. Agile Effort Estimation: Have We Solved the Problem Yet? Insights From a Replication Study. IEEE Transactions on Software Engineering 49, 4 (2023), 2677–2697. https://doi.org/10.
1109/TSE.2022.3228739
[^za]: Xiaohong Zhang. 2021. A comprehensive comparative study of clustering-based unsupervised defect prediction models. Journal of Systems and Software 172 (2021), 110862. 

Perhaps what is missing is a forum where resaercehrs can express the hereshy that some of our methods are overly-complex and that astonishingly simple methods can be astonishingly effective.
So let us create that forum.

In this call, which has no end date, we seek papers that revisit older results then perform 

- e.g. a study combining two methods, showing that task A can be better eprformed by B (where B is somehow "less"; i.e. smaller, simpler, faster);
- or e.g. ablation studies that throws away bits  of an implementation till  the performance drops;
- or e.g. some kind of  instance or feature selection to reduce the training set
- or e.g. some kind of distillation method to reduce the size of a learned model
- or e.g. some variance study that show that the apparent improvement of a complex method over a simpler one is actual insignificantly small
- or e.g. some study showing that a 10% system (measured in, say,  LOC) does as nearly as well  as the 100% system.
- or e.g. some other kind of study illustrating when less can be very much more.

## Deadline

None. This is an on-going track.

## Editor
Tim Menzies (timm@ieee.org)
